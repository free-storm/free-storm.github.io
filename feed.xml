<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>自由风暴</title>
  <subtitle>自由风暴</subtitle>
  <id>http://freestorm.org/</id>
  <link href="http://freestorm.org/"/>
  <link href="http://freestorm.org/feed.xml" rel="self"/>
  <updated>2015-10-09T00:00:00+08:00</updated>
  <author>
    <name>自由风暴</name>
  </author>
  <entry>
    <title>搭建 etcd 集群 - 暴走漫画容器实践系列 Part3</title>
    <link rel="alternate" href="/2015/10/09/搭建-etcd-集群.html"/>
    <id>/2015/10/09/搭建-etcd-集群.html</id>
    <published>2015-10-09T00:00:00+08:00</published>
    <updated>2015-10-09T00:00:00+08:00</updated>
    <author>
      <name>Michael Ding</name>
    </author>
    <summary type="html">&lt;p&gt;&lt;code&gt;etcd&lt;/code&gt; 是一个高可用的分布式 key-value(键值) 存储系统。在暴漫我们用他用来做配置管理和服务发现。&lt;/p&gt;

&lt;p&gt;这一次我们主要介绍关于 etcd 集群的搭建与管理。&lt;/p&gt;

&lt;h2&gt;1. etcd 集群概述&lt;/h2&gt;

&lt;p&gt;首先我们需要理解，&lt;code&gt;etcd&lt;/code&gt; 是一个分布式的 key-value 存储系统，所以其基本原理和前面我们介绍过的
&lt;a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E7%90%86%E8%AE%BA.html"&gt;分布式数据库相关理论&lt;/a&gt; 是一致的。&lt;/p&gt;

&lt;h3&gt;两种不同的 node(节点)&lt;/h3&gt;

&lt;p&gt;值得注意的是，为了方便使用，&lt;code&gt;etcd&lt;/code&gt; 引入了 &lt;code&gt;proxy&lt;/code&gt; 的概念，所以 &lt;code&gt;etcd&lt;/code&gt; 的节点分为两种：&lt;code&gt;集群节点&lt;/code&gt;和&lt;code&gt;代理节点&lt;/code&gt;。&lt;/p&gt;
...</summary>
    <content type="html">&lt;p&gt;&lt;code&gt;etcd&lt;/code&gt; 是一个高可用的分布式 key-value(键值) 存储系统。在暴漫我们用他用来做配置管理和服务发现。&lt;/p&gt;

&lt;p&gt;这一次我们主要介绍关于 etcd 集群的搭建与管理。&lt;/p&gt;

&lt;h2&gt;1. etcd 集群概述&lt;/h2&gt;

&lt;p&gt;首先我们需要理解，&lt;code&gt;etcd&lt;/code&gt; 是一个分布式的 key-value 存储系统，所以其基本原理和前面我们介绍过的
&lt;a href="/tags/分布式数据库相关理论.html"&gt;分布式数据库相关理论&lt;/a&gt; 是一致的。&lt;/p&gt;

&lt;h3&gt;两种不同的 node(节点)&lt;/h3&gt;

&lt;p&gt;值得注意的是，为了方便使用，&lt;code&gt;etcd&lt;/code&gt; 引入了 &lt;code&gt;proxy&lt;/code&gt; 的概念，所以 &lt;code&gt;etcd&lt;/code&gt; 的节点分为两种：&lt;code&gt;集群节点&lt;/code&gt;和&lt;code&gt;代理节点&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;集群节点&lt;/code&gt; 和 &lt;code&gt;代理节点&lt;/code&gt; 在使用上几乎没有任何区别。这使得我们可以在每台机器上都安装 &lt;code&gt;etcd&lt;/code&gt;，进而把 &lt;code&gt;etcd&lt;/code&gt; 当作本地服务来使用(通过 0.0.0.0)。
他们的区别在于：内部原理不同。
集群节点是真正的 &lt;code&gt;etcd&lt;/code&gt; 集群的构成者，这些节点负责数据存取，集群管理等等。
代理节点可以理解为一个反向代理，它只是简单的接受请求，转发请求给 &lt;code&gt;etcd&lt;/code&gt; 集群。&lt;/p&gt;

&lt;h3&gt;集群大小与容错&lt;/h3&gt;

&lt;p&gt;集群的大小指集群节点的个数。根据 &lt;code&gt;etcd&lt;/code&gt; 的分布式数据冗余策略，集群节点越多，容错能力(Failure Tolerance)越强，同时写性能也会越差。
所以关于集群大小的优化，其实就是容错和写性能的一个平衡。&lt;/p&gt;

&lt;p&gt;另外， etcd 推荐使用 &lt;code&gt;奇数&lt;/code&gt; 作为集群节点个数。因为奇数个节点与和其配对的偶数个节点相比(比如 3节点和4节点对比)，
容错能力相同，却可以少一个节点。&lt;/p&gt;

&lt;p&gt;所以综合考虑性能和容错能力，etcd 官方文档推荐的 etcd 集群大小是 &lt;strong&gt;3&lt;/strong&gt;, &lt;strong&gt;5&lt;/strong&gt;, &lt;strong&gt;7&lt;/strong&gt;。至于到底选择 3,5 还是 7，根据需要的容错能力而定。&lt;/p&gt;

&lt;p&gt;关于节点数和容错能力对应关系，如下表所示：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;集群大小&lt;/th&gt;
&lt;th&gt;最大容错&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;2. etcd 集群的搭建(初始化一个 etcd 集群)&lt;/h2&gt;

&lt;p&gt;这里说的搭建指“从无到有”搭建。关于在已有集群中添加减少集群节点，属于下面&amp;ldquo;&lt;strong&gt;第3节:etcd 集群的管理&lt;/strong&gt;&amp;quot;的内容。&lt;/p&gt;

&lt;p&gt;etcd 集群的搭建有三种方式，包括：static 方式，etcd discovery 方式 和 DNS discovery。&lt;/p&gt;

&lt;p&gt;这里，我们以一个例子来讲解 etcd 集群各种方式的搭建。假设我们需要搭建一个3节点的 etcd 集群。这三个节点的 name(我们需要给每个节点取个名字)和 ip 分别是：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;ip&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;etcd0&lt;/td&gt;
&lt;td&gt;10.0.0.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;etcd1&lt;/td&gt;
&lt;td&gt;10.0.0.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;etcd2&lt;/td&gt;
&lt;td&gt;10.0.0.12&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h3&gt;2.1 static 方式&lt;/h3&gt;

&lt;p&gt;static 方式是最简单的一种搭建 etcd 的方式。
不像其他两种方式， static 方式不需要任何额外的服务，只需要你知道你准备用来运行 etcd 的所有节点(的name和ip)。&lt;/p&gt;

&lt;p&gt;本例中，我们来看看如何在3个节点上构建 &lt;code&gt;etcd&lt;/code&gt; 集群。&lt;/p&gt;

&lt;p&gt;首先我们需要构造一个描述集群所有节点的参数，这个参数可以以&lt;strong&gt;命令行参数的方式&lt;/strong&gt;传给 &lt;code&gt;etcd&lt;/code&gt; 程序，也可以以&lt;strong&gt;环境变量的方式&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;如果用&lt;strong&gt;命令行参数&lt;/strong&gt;，应该将下列参数附在 &lt;code&gt;etcd&lt;/code&gt; 的启动命令后面：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;-initial-cluster &lt;span class="nv"&gt;etcd0&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.10:2380,etcd1&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.11:2380,etcd2&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster-state new
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;code&gt;-initial-cluster-state new&lt;/code&gt; 表示这是在从无到有搭建 etcd 集群。
&lt;code&gt;-initial-cluster&lt;/code&gt; 参数描述了这个新集群中总共有哪些节点，其中每个节点用 &lt;code&gt;name=ip&lt;/code&gt;的形式描述，节点之间用&lt;code&gt;,&lt;/code&gt;分隔。&lt;/p&gt;

&lt;p&gt;如果用&lt;strong&gt;环境变量&lt;/strong&gt;，应该在启动 &lt;code&gt;etcd&lt;/code&gt; 时，加入如下环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="nv"&gt;ETCD_INITIAL_CLUSTER&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"etcd0=http://10.0.1.10:2380,etcd1=http://10.0.1.11:2380,etcd2=http://10.0.1.12:2380"&lt;/span&gt;
&lt;span class="nv"&gt;ETCD_INITIAL_CLUSTER_STATE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;new
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ETCD_INITIAL_CLUSTER&lt;/code&gt; 变量和 &lt;code&gt;-initial-cluster&lt;/code&gt; 作用相同,
&lt;code&gt;ETCD_INITIAL_CLUSTER_STATE&lt;/code&gt; 变量和 &lt;code&gt;-initial-cluster-state&lt;/code&gt; 作用相同。&lt;/p&gt;

&lt;p&gt;接着，分别在3个节点上启动 &lt;code&gt;etcd&lt;/code&gt;，以&lt;strong&gt;命令行参数&lt;/strong&gt;方式启动为例：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;etcd -name etcd0 -initial-advertise-peer-urls http://10.0.1.10:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.10:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.10:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster-token my-etcd-cluster &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster &lt;span class="nv"&gt;etcd0&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.10:2380,etcd1&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.11:2380,etcd2&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster-state new
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;etcd -name etcd1 -initial-advertise-peer-urls http://10.0.1.11:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.11:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.11:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster-token my-etcd-cluster &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster &lt;span class="nv"&gt;etcd0&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.10:2380,etcd1&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.11:2380,etcd2&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster-state new
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;etcd -name etcd2 -initial-advertise-peer-urls http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.12:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster-token my-etcd-cluster &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster &lt;span class="nv"&gt;etcd0&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.10:2380,etcd1&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.11:2380,etcd2&lt;span class="o"&gt;=&lt;/span&gt;http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -initial-cluster-state new
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;值得注意的是，无论是 &lt;code&gt;-initial-cluster&lt;/code&gt;参数，还是对应的环境变量，只有在第一次启动 &lt;code&gt;etcd&lt;/code&gt; 的时候才起作用。
之后如果重启 &lt;code&gt;etcd&lt;/code&gt;，这个参数或环境变量会被自动忽略。所以当成功初始化了一个 &lt;code&gt;etcd&lt;/code&gt; 集群以后，你就不在需要这个参数或环境变量了。&lt;/p&gt;

&lt;h3&gt;2.2 etcd discovery 方式&lt;/h3&gt;

&lt;p&gt;很多时候，你只知道你要搭建一个多大(包含多少节点)的集群，但是并不能事先知道这几个节点的 ip，从而无法使用 &lt;code&gt;-initial-cluster&lt;/code&gt; 参数。
这个时候，你就需要使用 &lt;code&gt;discovery&lt;/code&gt; 的方式来搭建 &lt;code&gt;etcd&lt;/code&gt; 集群。discovery 方式有两种：&lt;code&gt;etcd discovery&lt;/code&gt; 和 &lt;code&gt;DNS discovery&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;这里我们先介绍下 &lt;code&gt;etcd discovery&lt;/code&gt; 方式，&lt;code&gt;etcd discovery&lt;/code&gt; 有两种：&lt;code&gt;自定义的 etcd discovery&lt;/code&gt; 和 &lt;code&gt;公共 etcd discovery&lt;/code&gt;&lt;/p&gt;

&lt;h4&gt;2.2.1 自定义的 etcd discovery 服务&lt;/h4&gt;

&lt;p&gt;这种方式就是&lt;strong&gt;利用一个已有的 &lt;code&gt;etcd&lt;/code&gt; 集群来提供 &lt;code&gt;discovery&lt;/code&gt; 服务，从而搭建一个新的 &lt;code&gt;etcd&lt;/code&gt; 集群。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;假设已有的 &lt;code&gt;etcd&lt;/code&gt; 集群的一个访问地址是：&lt;code&gt;myetcd.local&lt;/code&gt;，那么我们首先需要在已有 &lt;code&gt;etcd&lt;/code&gt; 中创建一个特殊的 key，方法如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;$ curl -X PUT https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83/_config/size -d value=3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;code&gt;value=3&lt;/code&gt; 表示本集群的大小，即: 有多少集群节点。而 &lt;code&gt;6c007a14875d53d9bf0ef5a6fc0257c817f0fb83&lt;/code&gt; 就是用来做 discovery 的 token。&lt;/p&gt;

&lt;p&gt;接下来你在 3 个节点上分别启动 &lt;code&gt;etcd&lt;/code&gt; 程序，并加上刚刚的 token。
加 token 的方式同样也有 &lt;strong&gt;命令行参数&lt;/strong&gt; 和 &lt;strong&gt;环境变量&lt;/strong&gt; 两种。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;命令行参数:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;-discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;环境变量&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;ETCD_DISCOVERY=https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以&lt;strong&gt;命令行参数&lt;/strong&gt;启动方式为例：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;etcd -name etcd0 -initial-advertise-peer-urls http://10.0.1.10:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.10:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.10:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;etcd -name etcd1 -initial-advertise-peer-urls http://10.0.1.11:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.11:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.11:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;etcd -name etcd2 -initial-advertise-peer-urls http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.12:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2.2.2 公共 etcd discovery 服务&lt;/h4&gt;

&lt;p&gt;如果没有已有的 &lt;code&gt;etcd&lt;/code&gt; 集群，也可以用 etcd 提供的公共服务: &lt;code&gt;discovery.etcd.io&lt;/code&gt;。
步骤和 &lt;strong&gt;2.2.1&lt;/strong&gt; 节基本一致。&lt;/p&gt;

&lt;p&gt;你得先创建一个用于 discovery 的 token，创建方式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;curl https://discovery.etcd.io/new?size&lt;span class="o"&gt;=&lt;/span&gt;3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回值作为启动节点时的 &lt;code&gt;-discovery&lt;/code&gt; 参数或者 &lt;code&gt;ETCD_DISCOVERY&lt;/code&gt;环境变量的值。&lt;/p&gt;

&lt;p&gt;以&lt;strong&gt;环境变量&lt;/strong&gt;启动方式为例：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;&lt;span class="nv"&gt;ETCD_DISCOVERY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de &lt;span class="se"&gt;\&lt;/span&gt;
etcd -name etcd0 -initial-advertise-peer-urls http://10.0.1.10:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.10:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.10:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;&lt;span class="nv"&gt;ETCD_DISCOVERY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de &lt;span class="se"&gt;\&lt;/span&gt;
etcd -name etcd1 -initial-advertise-peer-urls http://10.0.1.11:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.11:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.11:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;&lt;span class="nv"&gt;ETCD_DISCOVERY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de &lt;span class="se"&gt;\&lt;/span&gt;
etcd -name etcd2 -initial-advertise-peer-urls http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-peer-urls http://10.0.1.12:2380 &lt;span class="se"&gt;\&lt;/span&gt;
  -listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -advertise-client-urls http://10.0.1.12:2379 &lt;span class="se"&gt;\&lt;/span&gt;
  -discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.2.3 注意点&lt;/p&gt;

&lt;p&gt;值得注意的是：如果实际启动的 etcd 节点个数&lt;strong&gt;&lt;code&gt;大于&lt;/code&gt;&lt;/strong&gt; discovery token创建时指定的&lt;code&gt;size&lt;/code&gt;，
多余的节点会自动变为 &lt;code&gt;proxy&lt;/code&gt; 节点。&lt;/p&gt;

&lt;h3&gt;2.3 DNS discovery 方式&lt;/h3&gt;

&lt;p&gt;这个方式没有实践，而且对于一般团队实用性也不高，所以就不做分享了。&lt;/p&gt;

&lt;h3&gt;2.4 后续&lt;/h3&gt;

&lt;p&gt;到这里为止，我们已经有一个3节点的 &lt;code&gt;etcd&lt;/code&gt; 集群了，下一篇博客我会介绍如何进行 &lt;code&gt;etcd&lt;/code&gt; 集群的管理&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title/>
    <link rel="alternate" href="/2015/10/01/Docker-Docker-开源容器简介.html"/>
    <id>/2015/10/01/Docker-Docker-开源容器简介.html</id>
    <published>2015-10-01T00:00:00+08:00</published>
    <updated>2015-10-01T00:00:00+08:00</updated>
    <author>
      <name>自由风暴</name>
    </author>
    <summary type="html">&lt;hr&gt;

&lt;p&gt;title: Docker: 开源容器简介 - 暴走漫画容器实践系列 Part2
date: 2015-10-01
author: Michael Ding
tags:
- 分布式
- 容器
- 暴走漫画容器实践系列&lt;/p&gt;

&lt;h2&gt;published: false&lt;/h2&gt;
</summary>
    <content type="html">&lt;hr&gt;

&lt;p&gt;title: Docker: 开源容器简介 - 暴走漫画容器实践系列 Part2
date: 2015-10-01
author: Michael Ding
tags:
- 分布式
- 容器
- 暴走漫画容器实践系列&lt;/p&gt;

&lt;h2&gt;published: false&lt;/h2&gt;
</content>
  </entry>
  <entry>
    <title>在 Dockone 的分享 - 暴走漫画容器实践系列 Part1</title>
    <link rel="alternate" href="/2015/09/29/在Dockone的分享.html"/>
    <id>/2015/09/29/在Dockone的分享.html</id>
    <published>2015-09-29T00:00:00+08:00</published>
    <updated>2015-09-29T00:00:00+08:00</updated>
    <author>
      <name>Michael Ding</name>
    </author>
    <summary type="html">&lt;p&gt;大家好，我叫丁彦，来自暴走漫画。&lt;/p&gt;

&lt;p&gt;暴走漫画是一家文化传媒公司。公司除了有若干视频娱乐节目，还有相应的社区网站及 App。流量 UV 200w/天 左右，PV 千万。
为了更加有效地运营以及推荐用户个性化，2015年成立了数据部，负责暴漫的数据分析和数据挖掘相关服务。&lt;/p&gt;

&lt;p&gt;暴漫没有自己的服务器，是使用的国内某云服务。暴漫的后端主要是基于 Ruby 开发。也有基于 go, python 的一些micro service。
Docker 在暴漫中的应用主要包括：
* 开发环境的 service ...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;大家好，我叫丁彦，来自暴走漫画。&lt;/p&gt;

&lt;p&gt;暴走漫画是一家文化传媒公司。公司除了有若干视频娱乐节目，还有相应的社区网站及 App。流量 UV 200w/天 左右，PV 千万。
为了更加有效地运营以及推荐用户个性化，2015年成立了数据部，负责暴漫的数据分析和数据挖掘相关服务。&lt;/p&gt;

&lt;p&gt;暴漫没有自己的服务器，是使用的国内某云服务。暴漫的后端主要是基于 Ruby 开发。也有基于 go, python 的一些micro service。
Docker 在暴漫中的应用主要包括：
* 开发环境的 service 搭建
* 代码托管，持续集成，docker 镜像，等若干 support 服务
* 部分 micro service 以及整个数据服务系统&lt;/p&gt;

&lt;p&gt;所以今天的内容是一些中小规模以及国内云服务下的 docker 实践的相关心得，主要包括在数据服务的架构及 docker 化的部署。&lt;/p&gt;

&lt;h2&gt;1. 简单介绍下开发环境以及 support 服务的 docker 应用&lt;/h2&gt;

&lt;p&gt;由于开发环境主要是 Mac，也有少量 Ubuntu 和 Windows，所以主要采用 Vagrant + docker 方式。
将 micro service 做成 image，在 Vagrant 中起相应的container，把端口暴露给 Host(Vagrant)。本地跑 Ruby(on Rails)&lt;/p&gt;

&lt;p&gt;support 服务的话，其他都很简单，只有持续集成介绍下。我们用的 gitlab ci。gitlab ci 支持将 task 跑在 docker container 里面
所以我们为不同的项目准备不同的测试环境(image)以及外部依赖(eg. mysql, redis)，然后在对应的 container 里面跑测试。
关于部署的话，我们平时的开发在 develop 分支，一旦向 master 分支合并后，会触发部署的 task。
部署的 task 跑在特定的 container 里面，这个 container 共享了 Host 的 docker unix sock 文件，可以执行 docker build, push 等命令&lt;/p&gt;

&lt;p&gt;关于开发环境和 support 服务的 docker 应用，因为不是今天的重点，并且前面也有很多朋友做过类似的介绍，所以先简单介绍到这里。&lt;/p&gt;

&lt;h2&gt;2. micro service 和 数据服务系统的 docker 应用&lt;/h2&gt;

&lt;p&gt;今年我们做了很多 micro service 的尝试，例如消息推送，推荐系统，反垃圾系统，数据分析系统，视频抓取等等若干子系统的拆分上线。
虽然过程是痛苦的，但是结果却是令人欣慰的。这些 micro service，几乎都是基于 docker 的。&lt;/p&gt;

&lt;h3&gt;2.1 Rails + docker 化的 micro service&lt;/h3&gt;

&lt;p&gt;整体来说，我们是个混合的架构，Rails 是正常的跑在云主机中的，micro service 跑在 docker 中。为了协调好各方，我们对基础服务做了一点小小的调整。&lt;/p&gt;

&lt;p&gt;这里不得不说说我做架构的一点心得。好的架构除了能满足业务需求，还要是与特定的团队，特定的资源所配套的。
在暴漫，由于技术力量有限，开发排期满，所以我都是尽量采用“非侵入式”的方案，这在后面的数据服务的构建中也有体现。&lt;/p&gt;

&lt;p&gt;首先，我们给所有的机器都装上了 docker
其次，我们搭建了一个 etcd 集群，将所有的云主机都纳入了 etcd 集群。而 etcd 也是跑在 docker 里的。
为了方便的跑起来 etcd，我们写了个一套 bash + python 的脚本(Python 的脚本也是跑在 docker 里的)
然后，所有的机器直接访问本机 IP 可以 access etcd。&lt;/p&gt;

&lt;p&gt;这里插一句，我们没有去折腾如何让docker跨主机组网，而是直接采用映射到 host的方式。一方面国内云主机只能这么干。另一方面，我们之前使用云主机也是单个主机特定用途的。
另外，在生产环境中，我们大量的使用了 shell + etcd 来启动 docker container 的方式。可以给大家看个 etcd 的启动 script。这个 script 放到最初的机器上就可以方便地启动起来etcd 集群。&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight shell"&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

check_non_empty&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="c"&gt;# $1 is the content of the variable in quotes e.g. "$FROM_EMAIL"&lt;/span&gt;
  &lt;span class="c"&gt;# $2 is the error message&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; &lt;span class="nv"&gt;$1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;; &lt;span class="k"&gt;then
  &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"ERROR: specify &lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; -1
  &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

check_exec_success&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="c"&gt;# $1 is the content of the variable in quotes e.g. "$FROM_EMAIL"&lt;/span&gt;
  &lt;span class="c"&gt;# $2 is the error message&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; &lt;span class="nv"&gt;$1&lt;/span&gt; !&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"0"&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;; &lt;span class="k"&gt;then
  &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"ERROR: &lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="s2"&gt; failed"&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$3&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; -1
  &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

up&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

  &lt;span class="c"&gt;# create ${EtcdData}&lt;/span&gt;
  mkdir -p &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;EtcdData&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;

  &lt;span class="c"&gt;# pull pycsa docker image&lt;/span&gt;
  docker pull private/pycsa:latest

  check_exec_success &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$?&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="s2"&gt;"pulling 'pycsa' image"&lt;/span&gt;

  &lt;span class="c"&gt;# pull etcd docker image&lt;/span&gt;
  docker pull quay.io/coreos/etcd:latest

  check_exec_success &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$?&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="s2"&gt;"pulling 'etcd' image"&lt;/span&gt;

  &lt;span class="c"&gt;# build cluster nodes list for `-initial-cluster`&lt;/span&gt;
  &lt;span class="nv"&gt;cwd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
  &lt;span class="nv"&gt;ClusterNodes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;docker run --rm &lt;span class="se"&gt;\&lt;/span&gt;
    -v &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;cwd&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;:/data &lt;span class="se"&gt;\&lt;/span&gt;
    private/pycsa:latest &lt;span class="se"&gt;\&lt;/span&gt;
    python up.py cluster-nodes &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt; &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ETCD_NAME&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt; &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HostIP&lt;/span&gt;&lt;span class="k"&gt;})&lt;/span&gt;

    check_exec_success &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$?&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ClusterNodes&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;

    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt;
    &lt;span class="s2"&gt;"-a"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;BaseCmd&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt; -initial-cluster &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ClusterNodes&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    -initial-cluster-state existing
    &lt;span class="p"&gt;;;&lt;/span&gt;
    &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;BaseCmd&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt; -initial-cluster &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ClusterNodes&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    -initial-cluster-token bzetcd-cluster -initial-cluster-state new
    &lt;span class="p"&gt;;;&lt;/span&gt;
    &lt;span class="k"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"Usage: ./etcd.sh up [-a]"&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
    &lt;span class="p"&gt;;;&lt;/span&gt;
    &lt;span class="k"&gt;esac&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;

  start&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    docker &lt;span class="nb"&gt;kill &lt;/span&gt;etcd 2&amp;gt;/dev/null
    docker rm etcd 2&amp;gt;/dev/null
    &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;BaseCmd&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;

  stop&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    docker stop etcd
    docker rm etcd
  &lt;span class="o"&gt;}&lt;/span&gt;


  &lt;span class="c"&gt;##################&lt;/span&gt;
  &lt;span class="c"&gt;# Start of script&lt;/span&gt;
  &lt;span class="c"&gt;##################&lt;/span&gt;

  &lt;span class="c"&gt;# source env&lt;/span&gt;
  . /etc/default/etcd

  check_non_empty &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ETCD_NAME&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="s2"&gt;"ETCD_NAME"&lt;/span&gt;

  &lt;span class="c"&gt;# get host ip&lt;/span&gt;
  &lt;span class="nv"&gt;HostIP&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;ifconfig eth0 | awk &lt;span class="s1"&gt;'/\&amp;lt;inet\&amp;gt;/ { print $2}'&lt;/span&gt; | sed &lt;span class="s1"&gt;'s/addr://g'&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;

  &lt;span class="c"&gt;# set data dir&lt;/span&gt;
  &lt;span class="nv"&gt;EtcdData&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/data/etcd/data

  &lt;span class="c"&gt;# create etcd container base cmd&lt;/span&gt;
  &lt;span class="nv"&gt;BaseCmd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"docker run -d &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -v /usr/share/ca-certificates/:/etc/ssl/certs &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -v &lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;EtcdData&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;:/data &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -p 4001:4001 -p 2380:2380 -p 2379:2379 &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  --name etcd quay.io/coreos/etcd:latest &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -name &lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ETCD_NAME&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -data-dir /data &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -advertise-client-urls http://&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HostIP&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;:2379,http://&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HostIP&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;:4001 &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -listen-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -initial-advertise-peer-urls http://&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HostIP&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;:2380 &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;&lt;span class="s2"&gt;
  -listen-peer-urls http://0.0.0.0:2380"&lt;/span&gt;

  &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="k"&gt;in
  &lt;/span&gt;up&lt;span class="p"&gt;)&lt;/span&gt; up &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="p"&gt;;;&lt;/span&gt;
  start&lt;span class="p"&gt;)&lt;/span&gt; start &lt;span class="p"&gt;;;&lt;/span&gt;
  stop&lt;span class="p"&gt;)&lt;/span&gt; stop &lt;span class="p"&gt;;;&lt;/span&gt;
  restart&lt;span class="p"&gt;)&lt;/span&gt;
  stop
  start
  &lt;span class="p"&gt;;;&lt;/span&gt;
  &lt;span class="k"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"Usage: ./etcd.sh start|stop|restart or ./etcd.sh up [-a]"&lt;/span&gt;
  &lt;span class="nb"&gt;exit &lt;/span&gt;1
  &lt;span class="p"&gt;;;&lt;/span&gt;
  &lt;span class="k"&gt;esac&lt;/span&gt;

  &lt;span class="nb"&gt;exit &lt;/span&gt;0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;解释下， &lt;code&gt;up.py&lt;/code&gt; 是个 python 的脚本，跑在一个 pycsa 的容器里，这个容器有 python 环境以及相关的 package&lt;/p&gt;

&lt;p&gt;这样原来的服务几乎不受任何影响，我们可以利用 etcd + docker + shell script 来组建新的服务。&lt;/p&gt;

&lt;h3&gt;2.2 数据服务&lt;/h3&gt;

&lt;p&gt;我们的数据服务包括数据分析和数据挖掘两大块。数据分析主要是为了给运营提供量化的效果评估以及指导。数据挖掘则包括推荐，反垃圾等。&lt;/p&gt;

&lt;p&gt;数据服务的基础是数据流，即：数据收集-&amp;gt;数据分发-&amp;gt;数据处理&amp;lt;-&amp;gt;数据存储&lt;/p&gt;

&lt;p&gt;先给大家看个整体的架构图，由于本人不擅作图，所以直接用手画的，还请见谅。。&lt;/p&gt;

&lt;p&gt;&lt;img alt="fig" src="/images/baozou-data-arch-3a482905.png" /&gt;&lt;/p&gt;

&lt;p&gt;首先数据收集部分，就像之前说的，我尽量采用“非侵入式”的方案，所以，我们的整个数据收集都是基于日志的。
我们在每个应用服务器上装了 logstash (跑在 docker 中) 来收集各个应用服务器的日志，然后打到 kafka (跑在 docker 中) 里，给不同的用途使用。&lt;/p&gt;

&lt;p&gt;一份COPY 直接由kafka 一端的 logstash 存储到 elasticsearch(跑在 docker 中) 中
一份COPY 经过 spark (跑在 docker 中) stream 做实时处理(包括一些特定日志的提取)，然后将处理的结果存储在 elasticsearch 里
还有一份 COPY 直接存储到 HDFS (由云服务商提供)&lt;/p&gt;

&lt;p&gt;这里有个小问题，比如有些数据本身日志里并没有，比如用户的点击行为。这个时候，我们专门开发了一些 &amp;ldquo;ping&amp;rdquo; 接口，这些接口通过 Nginx 直接返回 200，并记录相关日志&lt;/p&gt;

&lt;p&gt;此外还有一部分数据，例如一些比较需要“较严格的完备”的，例如用于推荐系统，反垃圾系统学习的数据，我们存储在 SQL 数据库中&lt;/p&gt;

&lt;p&gt;下面我做些稍微详细的介绍&lt;/p&gt;

&lt;h4&gt;2.2.1 数据分析&lt;/h4&gt;

&lt;p&gt;数据分析有两种：实时数据分析和离线数据分析&lt;/p&gt;

&lt;p&gt;实时数据分析从 kafka 到 spark stream，处理结果进 elasticsearch，离线分析是定时任务，从 HDFS 到 spark，处理结果进 elasticsearch。一般来说，离线的结果会逐步包含实时的结果，
同时实时的结果领先于离线分析的结果。&lt;/p&gt;

&lt;p&gt;这里的分析有些抽象，我来举个例子：&lt;/p&gt;

&lt;p&gt;Q: 统计某个板块同时在线人数的变化趋势
A: 用户每次访问都有日志，日志里包括访问内容以及用户标识。首先 spark stream 从日志里抽取出特定板块不同用户的访问事件，以秒为单位合并相同用户事件。这就是分析结果：时间戳：人数&lt;/p&gt;

&lt;p&gt;然后这个结果怎么用？&lt;/p&gt;

&lt;p&gt;elasticsearch 有很强大的 agg 接口。你可以以1秒，10秒，1分等等各种时间间隔单位聚合这段时间内的在线人数，聚合方式用 &amp;lsquo;平均&amp;#39;或&amp;#39;最大&amp;rsquo;&lt;/p&gt;

&lt;h4&gt;2.2.2 数据挖掘&lt;/h4&gt;

&lt;p&gt;我们主要做了2个具体的数据挖掘系统：推荐+反垃圾&lt;/p&gt;

&lt;p&gt;今天主要讲下架构。&lt;/p&gt;

&lt;p&gt;这两个系统基本上步骤是一样的，分为2步：训练(train) 和 服务(serve)&lt;/p&gt;

&lt;p&gt;在 train 阶段，定时起一个 spark job，从训练数据集中读取数据，学习出 model，然后将 model 存储成文件
在 serve 阶段，起一个带 serve 的 spark job，load 之前学习出来的model 文件进内存，然后接受外部api 调用，返回结果。&lt;/p&gt;

&lt;p&gt;关于服务的开发这部分因为涉及到太多额外的知识，我就不多说了。&lt;/p&gt;

&lt;p&gt;这里讲个难点：spark 的 docker 化。&lt;/p&gt;

&lt;h4&gt;2.2.3 Spark 的 docker 化&lt;/h4&gt;

&lt;p&gt;Spark 的 docker 化分为两个部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;docker 化的 spark 集群&lt;/li&gt;
&lt;li&gt;docker 化的 spark 调用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Spark 和我们一般用的服务不太一样，它的集群不是提供运算服务的，而是一种资源分配的调度器。
让 Spark 跑 Job，其实是起的一个 Spark 的本地程序，这个本地程序会向 cluster 要资源(其他机器)，cluster 分配资源以后，这个 spark 程序就把一些工作放在这些资源当中运行(进程)&lt;/p&gt;

&lt;p&gt;所以 Spark 的 docker 化分为两个部分。&lt;/p&gt;

&lt;p&gt;对于 spark 调用，也就是启动 spark 的本地程序，我们就是在跑程序的 image 中集成 java 环境，spark 程序&lt;/p&gt;

&lt;p&gt;对于 spark 集群，稍微复杂一些。spark 支持三种集群：mesos, yard，还有 spark 自己的一个 standalone
我们搭建的 spark standalone 集群，这还是考虑到我们自身的资源与需求。&lt;/p&gt;

&lt;p&gt;由于没找到官方的 spark docker image，我们自己做了一个，就是 java 环境 + spark 程序
然后利用 script + etcd 以不同的姿势(master 或 slave)在不同的云主机上启动 spark container&lt;/p&gt;

&lt;p&gt;官方推荐要起3个 master, 用 zookeeper 做 quorum，这个我们最近正在搞，还没上线，就不分享。我们现在线上跑的是 1 master  + 7 slave&lt;/p&gt;

&lt;p&gt;谢谢&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Spark 集群概述</title>
    <link rel="alternate" href="/2015/07/22/spark-cluster.html"/>
    <id>/2015/07/22/spark-cluster.html</id>
    <published>2015-07-22T00:00:00+08:00</published>
    <updated>2015-07-22T00:00:00+08:00</updated>
    <author>
      <name>Michael Ding</name>
    </author>
    <summary type="html">&lt;p&gt;本篇博客简述 Spark 集群相关的概念。&lt;/p&gt;

&lt;h2&gt;概述&lt;/h2&gt;

&lt;p&gt;Spark 的"集群“不是提供运算服务的，而是一种资源分配的调度器。
执行任务的 Spark 进程作为客户端向"集群"申请资源(运算节点), "集群"分配资源以后，
这个 Spark 进程会分解一些计算工作，并把他们放到这些申请来的资源中运行。&lt;/p&gt;

&lt;p&gt;提交给 Spark 执行的工作称做 &lt;code&gt;application&lt;/code&gt;(应用)，对应的主程序称作：&lt;code&gt;driver program&lt;/code&gt;。
&lt;code&gt;driver program&lt;/code&gt; 通过一个叫做 &lt;code&gt;SparkContext&lt;/code&gt; 的对...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;本篇博客简述 Spark 集群相关的概念。&lt;/p&gt;

&lt;h2&gt;概述&lt;/h2&gt;

&lt;p&gt;Spark 的&amp;quot;集群&amp;ldquo;不是提供运算服务的，而是一种资源分配的调度器。
执行任务的 Spark 进程作为客户端向&amp;quot;集群&amp;quot;申请资源(运算节点), &amp;quot;集群&amp;quot;分配资源以后，
这个 Spark 进程会分解一些计算工作，并把他们放到这些申请来的资源中运行。&lt;/p&gt;

&lt;p&gt;提交给 Spark 执行的工作称做 &lt;code&gt;application&lt;/code&gt;(应用)，对应的主程序称作：&lt;code&gt;driver program&lt;/code&gt;。
&lt;code&gt;driver program&lt;/code&gt; 通过一个叫做 &lt;code&gt;SparkContext&lt;/code&gt; 的对象来协调 Spark 集群中不同进程的任务。&lt;/p&gt;

&lt;p&gt;具体来说：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;driver program&lt;/code&gt; 向&amp;quot;集群&amp;quot;申请到得运算节点称作 worker node；&lt;/li&gt;
&lt;li&gt;一旦申请到 worker node，&lt;code&gt;driver program&lt;/code&gt; 会连接这些 worker node, 并在 worker node 上创建(acquire)执行计算的进程(&lt;code&gt;executor&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;接下来 &lt;code&gt;driver program&lt;/code&gt; 将计算需要的代码和数据发给 &lt;code&gt;executor&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;最后 &lt;code&gt;SparkContext&lt;/code&gt; 将分解出来的 &lt;code&gt;task&lt;/code&gt;(任务) 发送给各个 &lt;code&gt;executor&lt;/code&gt; 去执行。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;过程如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img alt="Spark Cluster Overview" src="/images/spark-cluster-overview-d2fa24f9.png" /&gt;&lt;/p&gt;

&lt;p&gt;这里有一些注意点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;每个 &lt;code&gt;application&lt;/code&gt; 都获得自己独立的 &lt;code&gt;executor&lt;/code&gt; 进程，这个&lt;code&gt;executor&lt;/code&gt;进程利用多个线程运行多个 &lt;code&gt;task&lt;/code&gt;。这样可以保证不同&lt;code&gt;application&lt;/code&gt;的隔离性，无论是调度端(&lt;code&gt;driver program&lt;/code&gt; 分解各自的 &lt;code&gt;task&lt;/code&gt;)，还是执行端(每个&lt;code&gt;executor&lt;/code&gt;只跑来自同一个 &lt;code&gt;application&lt;/code&gt; 的 &lt;code&gt;task&lt;/code&gt;)。不过这也意味着，不同的 &lt;code&gt;application&lt;/code&gt; 之间除非借助外部存储系统(例如数据库)，否则是不可以共享数据的。&lt;/li&gt;
&lt;li&gt;Spark 是不需要知道运行在什么样的 &amp;quot;集群&amp;rdquo; 上的。Spark 只需要可以创建进程，并且和这些进程通信，无论是运行在什么样的集群上(eg. Mesos/YARN)都可以。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;driver program&lt;/code&gt; 必须在整个生命周期中可以从不同的 &lt;code&gt;executor&lt;/code&gt; 接受连接。因此，&lt;code&gt;driver program&lt;/code&gt;对于 &lt;code&gt;executor&lt;/code&gt; 来说，
必须是网路可及的。&lt;/li&gt;
&lt;li&gt;因为由&lt;code&gt;driver program&lt;/code&gt;分解 &lt;code&gt;task&lt;/code&gt;，它必须和 &lt;code&gt;worker&lt;/code&gt; 节点很接近，最好在同一个局域网。
如果你不能做到这一点(例如从远程提交 &lt;code&gt;application&lt;/code&gt;)，最好开一个 RPC，利用靠近 Spark 集群的机器来运行 &lt;code&gt;driver program&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Spark 集群的类型&lt;/h2&gt;

&lt;p&gt;实现集群的程序称为：&lt;code&gt;集群管理器&lt;/code&gt;。目前有三种&lt;code&gt;集群管理器&lt;/code&gt;：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://spark.apache.org/docs/latest/spark-standalone.html"&gt;Standalone&lt;/a&gt; - 这个集群管理器打包在 spark 的程序里，是最简单的集群管理器。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://spark.apache.org/docs/latest/running-on-mesos.html"&gt;Apache Mesos&lt;/a&gt; - 一个非常成熟的分布式操作系统，可以用来运行除 Spark 以外的很多系统。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://spark.apache.org/docs/latest/running-on-yarn.html"&gt;Hadoop YARN&lt;/a&gt; - Hadoop 的 资源管理器。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;术语表&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;术语&lt;/th&gt;
&lt;th&gt;解释&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Application&lt;/td&gt;
&lt;td&gt;在 Spark 上运行的工作， 由 &lt;code&gt;driver program&lt;/code&gt; 和 &lt;code&gt;executors&lt;/code&gt; 组成&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Application jar&lt;/td&gt;
&lt;td&gt;包含 Application 代码的 jar 包。在一些应用场景中，jar 需要包含依赖的库。不过永远不要包含 Hadoop 和  Spark 的库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Driver program&lt;/td&gt;
&lt;td&gt;运行 Application 的&lt;code&gt;main()&lt;/code&gt; 函数的进程，并且 SparkContext 对象在此进程中创建&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cluster manager(集群管理器)&lt;/td&gt;
&lt;td&gt;实现集群的资源调度分配的外部程序&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Deploy mode&lt;/td&gt;
&lt;td&gt;用于区分 &lt;code&gt;driver program&lt;/code&gt; 进程在哪里运行。&lt;code&gt;cluster&lt;/code&gt; 模式下，&lt;code&gt;driver&lt;/code&gt; 在集群中的节点上运行。 &lt;code&gt;client&lt;/code&gt; 模式下，&lt;code&gt;driver&lt;/code&gt; 在集群以外的地方运行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Worker node&lt;/td&gt;
&lt;td&gt;集群中运行程序的节点&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Executor&lt;/td&gt;
&lt;td&gt;在 &lt;code&gt;worker node&lt;/code&gt; 中为 各 Application 创建的进程。它会执行 Application 相关的 task，将它们的数据保存在内存中或磁盘上。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Task&lt;/td&gt;
&lt;td&gt;执行具体计算的单元，会被发送给特定的 &lt;code&gt;executor&lt;/code&gt; 执行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Job&lt;/td&gt;
&lt;td&gt;一个由多个 &lt;code&gt;task&lt;/code&gt; 组成的并行计算集，它们生成 Spark 动作(eg. save, collect) 的结果。这个术语会出现在 &lt;code&gt;driver&lt;/code&gt; 的日志中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stage&lt;/td&gt;
&lt;td&gt;每个 &lt;code&gt;job&lt;/code&gt; 会被分解成更小的 &lt;code&gt;task&lt;/code&gt; 的集合，这些集合被称作 &lt;code&gt;stage&lt;/code&gt;。它们彼此依赖(就像 MapReduce 中的 map 和 reduce 两个 &lt;code&gt;stage&lt;/code&gt;)；这个术语会出现在 &lt;code&gt;driver&lt;/code&gt; 的日志中&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</content>
  </entry>
  <entry>
    <title>冲突的处理 - 分布式数据库相关理论 Part5</title>
    <link rel="alternate" href="/2015/04/29/冲突的处理.html"/>
    <id>/2015/04/29/冲突的处理.html</id>
    <published>2015-04-29T00:00:00+08:00</published>
    <updated>2015-04-29T00:00:00+08:00</updated>
    <author>
      <name>Michael Ding</name>
    </author>
    <summary type="html">&lt;p&gt;冲突的处理，也是分布式系统中一个重要的议题。今天我们继续以 Riak 为案例，看看 Riak 是怎么做冲突处理的。&lt;/p&gt;

&lt;h2&gt;Vector Clock(向量钟)&lt;/h2&gt;

&lt;p&gt;Riak 通过一种叫做 &lt;code&gt;Vector Clock&lt;/code&gt; 的机制来处理冲突问题。简单来说，&lt;code&gt;Vector Clock&lt;/code&gt; 是一段 &lt;code&gt;token&lt;/code&gt;，
像 &lt;code&gt;Riak&lt;/code&gt; 这样的分布式系统通过这样的 &lt;code&gt;token&lt;/code&gt; 来追踪数据更新操作的先后顺序。&lt;/p&gt;

&lt;p&gt;在冲突处理中，能够知道冲突操作(eg. 创建操作，更改操作)的顺序，是非常重要的。
因为对于分布式系统来说，不同的客户端...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;冲突的处理，也是分布式系统中一个重要的议题。今天我们继续以 Riak 为案例，看看 Riak 是怎么做冲突处理的。&lt;/p&gt;

&lt;h2&gt;Vector Clock(向量钟)&lt;/h2&gt;

&lt;p&gt;Riak 通过一种叫做 &lt;code&gt;Vector Clock&lt;/code&gt; 的机制来处理冲突问题。简单来说，&lt;code&gt;Vector Clock&lt;/code&gt; 是一段 &lt;code&gt;token&lt;/code&gt;，
像 &lt;code&gt;Riak&lt;/code&gt; 这样的分布式系统通过这样的 &lt;code&gt;token&lt;/code&gt; 来追踪数据更新操作的先后顺序。&lt;/p&gt;

&lt;p&gt;在冲突处理中，能够知道冲突操作(eg. 创建操作，更改操作)的顺序，是非常重要的。
因为对于分布式系统来说，不同的客户端连接到的是不同的服务器节点，
当一个客户端更新了一个服务器节点上的数据，也许另一个客户端也同时更新了另一个服务器节点上的数据。&lt;/p&gt;

&lt;p&gt;这时候，也许你会想到：记录每个操作的时间戳，然后依照时间戳靠后的操作来。然而要这么做的话，这里有个隐含的前提：
在这个分布式系统中的每个服务器节点，时钟都必须是完全同步的。
然而事实上，一方面这是非常困难的：需要非常大的财力物力的投入；另一方面，整个系统又是单点故障的。&lt;/p&gt;

&lt;p&gt;所以，Riak 使用 &lt;code&gt;Vector Clocks&lt;/code&gt; 来处理冲突。&lt;code&gt;Vector Clocks&lt;/code&gt; 给每个写操作(创建，更改，删除) 打上一个标签，标签代表了是哪个客户端以什么样的顺序执行的操作。
这样一来，客户端或者开发者就能决定面对冲突，该怎么决定。
如果你熟悉像 &lt;code&gt;Git&lt;/code&gt;, &lt;code&gt;Subversion&lt;/code&gt;这样的版本控制系统，
这就和两个人同时修改了同一个文件产生的冲突解决思路是相似的。&lt;/p&gt;

&lt;h3&gt;&lt;code&gt;Vector Clock&lt;/code&gt; 小故事 —— &lt;code&gt;Vector Clock&lt;/code&gt; 相关理论&lt;/h3&gt;

&lt;p&gt;暴走大事件的编辑部每周都要整理下一期里要播报的新闻段子。&lt;/p&gt;

&lt;p&gt;假设负责整理新闻段子有3个人：王尼玛(A), 张全蛋(B), 纸巾&amp;copy;。他们需要确定最终的新闻段子的列表。新闻段子的列表存储在分布式的服务器中。&lt;/p&gt;

&lt;p&gt;每个人用自己的终端连接数据库。这些终端都有着唯一的标识，用来构建 vector clock。下面就让我们模拟一下，vector clock 是如何工作的。&lt;/p&gt;

&lt;p&gt;首先，王尼玛用自己的终端更新了列表&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;vclock: A[0]
value: ['news xx']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后，张全蛋先下载了这个列表，然后更新了这个列表&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;vclock: A[0], B[0]
value: ['news xx', 'news xyy']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;张全蛋更新的同时(王尼玛做更新之后)，纸巾同样的下载了已有的列表，做了更新。&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;vclock: A[0], C[0]
value: ['news xx', 'news yyz']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二天，张全蛋复查列表，由于纸巾的更新操作并不是在他之后的(而是和他同时的)，
这时候就产生了一个冲突，需要处理。&lt;/p&gt;

&lt;p&gt;他拿到两个值：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;vclock: A[0], B[0]
value: ['news xx', 'news xyy']
--
vclock: A[0], C[0]
value: ['news xx', 'news yyz']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他需要解决这个冲突：于是他选择合并这两个值：&lt;/p&gt;
&lt;pre&gt;&lt;code class="highlight plaintext"&gt;vclock: A[0], C[0], B[1]
value: ['news xx', 'news xyy', 'news yyz']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样一来，任何人之后获取到的就是这个最新的合并后的值了。&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Riak 中的 CAP - 分布式数据库相关理论 Part4</title>
    <link rel="alternate" href="/2015/04/28/Riak中的CAP.html"/>
    <id>/2015/04/28/Riak中的CAP.html</id>
    <published>2015-04-28T00:00:00+08:00</published>
    <updated>2015-04-28T00:00:00+08:00</updated>
    <author>
      <name>Michael Ding</name>
    </author>
    <summary type="html">&lt;p&gt;和&lt;a href="2015/04/25/Riak%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A8%A1%E5%9E%8B.html"&gt;上一篇博文&lt;/a&gt;一样，这次我们依旧以 Riak 为案例，来分析 &lt;code&gt;CAP&lt;/code&gt; 理论在一个实际的分布式数据库中的作用。&lt;/p&gt;

&lt;p&gt;如果你还不熟悉 &lt;code&gt;CAP&lt;/code&gt;，可以参考我之前的两篇博客 &lt;a href="/2015/04/22/%E7%90%86%E8%A7%A3CAP%E7%90%86%E8%AE%BA.html"&gt;理解 CAP 理论&lt;/a&gt;, &lt;a href="/2015/04/23/Eventual-Consistency(%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7).html"&gt;最终一致性&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;这次我们来看看，在 Riak 这样的分布式key-value数据库中，&lt;code&gt;CAP&lt;/code&gt;理论是怎么起作用的。&lt;/p&gt;

&lt;h2&gt;Nodes/Writes/Reads&lt;/h2&gt;

&lt;p&gt;首先还是让我们来明确几个概念。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;N&lt;/strong&gt; odes&lt;/p&gt;

&lt;p&gt;需要"最终"包含正确的值的服务器节点总数(正确的冗余数据拷贝数)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;W&lt;/strong&gt; rites&lt;/p&gt;

&lt;p&gt;每次写操作，我们需...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;和&lt;a href="2015/04/25/Riak%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A8%A1%E5%9E%8B.html"&gt;上一篇博文&lt;/a&gt;一样，这次我们依旧以 Riak 为案例，来分析 &lt;code&gt;CAP&lt;/code&gt; 理论在一个实际的分布式数据库中的作用。&lt;/p&gt;

&lt;p&gt;如果你还不熟悉 &lt;code&gt;CAP&lt;/code&gt;，可以参考我之前的两篇博客 &lt;a href="/2015/04/22/%E7%90%86%E8%A7%A3CAP%E7%90%86%E8%AE%BA.html"&gt;理解 CAP 理论&lt;/a&gt;, &lt;a href="/2015/04/23/Eventual-Consistency(%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7).html"&gt;最终一致性&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;这次我们来看看，在 Riak 这样的分布式key-value数据库中，&lt;code&gt;CAP&lt;/code&gt;理论是怎么起作用的。&lt;/p&gt;

&lt;h2&gt;Nodes/Writes/Reads&lt;/h2&gt;

&lt;p&gt;首先还是让我们来明确几个概念。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;N&lt;/strong&gt; odes&lt;/p&gt;

&lt;p&gt;需要&amp;quot;最终&amp;quot;包含正确的值的服务器节点总数(正确的冗余数据拷贝数)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;W&lt;/strong&gt; rites&lt;/p&gt;

&lt;p&gt;每次写操作，我们需要确保最少有多少节点被更新。也就是说，我们在执行写操作的时候，不需要等待 N 个节点都成功被写入，
而只需要 W 个节点成功写入，这次写操作就返回成功，而其他节点是在后台进行同步。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; eads&lt;/p&gt;

&lt;p&gt;每次读操作，我们需要确保最少读到几份冗余数据。也就是说，我们在执行读操作的时候，需要读到 R 个节点的数据才算读成功，否则读取失败。&lt;/p&gt;

&lt;p&gt;为什么要这三个变量？其实这三个变量直接关系到了 Riak 的 CAP 特性。下面我们就来一一说明：&lt;/p&gt;

&lt;h2&gt;Eventual Consistency(W + R &amp;lt;= N)&lt;/h2&gt;

&lt;p&gt;如下图所示：假设我们的 N=3, 设置 W + R &amp;lt;= N(例如：R=2, W=1)。这样我们的系统可以相对保证读写性能。
因为写操作只需要一个节点写入就返回成功。&lt;/p&gt;

&lt;p&gt;&lt;img alt="fig1" src="/images/w+r&amp;lt;=n-e653dec0.png" /&gt;&lt;/p&gt;

&lt;p&gt;然而这里有机率发生这样的情况：就像图中所示，我写入的是node1(versionB)，然后进行了一次读操作。
恰好这时候新数据尚未同步到node2, node3，而读操作又是从node2，node3取的值。由于这两个节点的值都是 version A，
所以得到的值便是 version A。&lt;/p&gt;

&lt;p&gt;不过随着时间的推移，node1 中的 versionB 会被同步到 node2 以及 node3 中。
这时候，再有读操作，得到的值便是最新值(versionB)了。&lt;/p&gt;

&lt;p&gt;这就是所谓的 Eventual Consistency。整个系统有着较高的读写性能，但一致性有所牺牲。&lt;/p&gt;

&lt;p&gt;如果我们需要加强一致性，可以通过调整 W, R, N 来实现。&lt;/p&gt;

&lt;p&gt;接下来我们会讨论如何调整 W，R，N 的关系来平衡读写性能和一致性(即 A 和 C 的平衡)。&lt;/p&gt;

&lt;h2&gt;通过调节 W,R,N 的关系来调节一致性和读写性能的关系&lt;/h2&gt;

&lt;p&gt;一种极端做法(下图所示)，我们可以设 W=N, R=1。其实这就是关系型数据库的做法。
通过确保每次写操作时，所有相关节点都被成功写入，来确保一致性。这样可以保证一致性，但是牺牲了写操作的性能。&lt;/p&gt;

&lt;p&gt;&lt;img alt="fig2" src="/images/w=nr=1-03f259cf.png" /&gt;&lt;/p&gt;

&lt;p&gt;还有一种极端做法，我们可以设W=1, R=N。这样，无论你向哪个node写入了数据，都会被读到。
然后你读到的N个值也可能包含旧的值，只要有办法分辨出哪个是最新的值就可以了
(Riak 是用一直叫向量钟(Vector Clock)的技术来判断的，我们会在后面的博客中做介绍)
这样可以保证一致性，但是牺牲了读操作的性能。&lt;/p&gt;

&lt;p&gt;&lt;img alt="fig3" src="/images/w=1r=n-d16553e5.png" /&gt;&lt;/p&gt;

&lt;p&gt;最后再给出一种被称作 &lt;code&gt;quorum&lt;/code&gt; 的做法。如下图所示，可以设置 W + R &amp;gt; N (例如 W=2, R=2)。这样同样可以保证一致性。
然而性能的损失由写操作和读操作共同承担。这种做法叫做 &lt;code&gt;quorum&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img alt="fig4" src="/images/w+r&amp;gt;n-a4cdd279.png" /&gt;&lt;/p&gt;
</content>
  </entry>
</feed>
